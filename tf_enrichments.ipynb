{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATSS Text-Fabric Enrichments\n",
    "\n",
    "The raw data from the CCAT resource has been converted into a TF format in `tf_conversion.ipynb`. This notebook enriches the dataset in a number of ways:\n",
    "\n",
    "* Morphological tags are split and parsed into individual word-level features.\n",
    "* Word-level plain-text is processed into a UTF8 representation feature.\n",
    "* A first effort is made to connect the ETCBC BHSA Hebrew database with the CATSS Hebrew parallel text using parts of speech for word-level connections. Phrase-level connections are created based on phrases' presence per line.\n",
    "* Some rudimentary phrase divisions are also added the CATSS data based on the parallel data. \n",
    "\n",
    "## Instantiate CATSS TF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.1.1\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "10 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s B book                 from tf\n",
      "   |     0.00s B chapter              from tf\n",
      "   |     0.01s B verse                from tf\n",
      "   |     0.19s B trans                from tf\n",
      "   |     0.21s B morph                from tf\n",
      "   |     0.00s Feature overview: 8 for nodes; 1 for edges; 1 configs; 7 computed\n",
      "  0.91s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=['tf'], modules=[''])\n",
    "\n",
    "api = TF.load('book chapter verse morph trans')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Morphology Features\n",
    "\n",
    "See the [CATSS morphology documentation](http://ccat.sas.upenn.edu/gopher/text/religion/biblical/lxxmorph/*Morph-Coding). In the source data, morphology is space-separated. In the TF version they are dot separated. Tags have to be split, recognized, and converted. They are added as separate word-level features.\n",
    "\n",
    "Morphology codes have 3 or 2 columns, depending on part of speech type. From the documentation:\n",
    "\n",
    "> 1. \"TYPE\" CODES (3 columns maximum, to identify part of speech)\n",
    "> 2. \"PARSE\" CODE (up to 6 columns, as needed, to parse each form) [\\*OPTIONAL]\n",
    "> 3. [lexeme]\n",
    "\n",
    "Proposals for new features:\n",
    "\n",
    "* typ — part of speech, derived from the type codes. It is the first letter of the type code and can have a values of (bold is proposed new feature name):\n",
    "    * N — noun — **noun**\n",
    "    * A — adjective — **adjv**\n",
    "    * R — pronoun — **pron**\n",
    "    * C — conjunction — **conj**\n",
    "    * X — particle — **part**\n",
    "    * I — interjection — **intj**\n",
    "    * M — indeclinable number — **inum**\n",
    "    * P — preposition — **prep**\n",
    "    * D — adverb — **advb**\n",
    "* **styp** — subtype of part of speech, e.g. 1st declension, 3rd declension of various stems. There are lots of categories. The simple code is preserved. Refer to the documentation for their meanings. For that code, I preserve also the part of speech value (N, A, R, etc.)\n",
    "\n",
    "* case — **case**\n",
    "* gender — **gender**\n",
    "* number — **number**\n",
    "* tense — **tense**\n",
    "* voice — **voice**\n",
    "* mood — **mood**\n",
    "* person — **person**\n",
    "* degree — **degree**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E)N  —  P.E)N\n",
      "A)RXH=|  —  N1.DSF.A)RXH/\n",
      "E)POI/HSEN  —  VAI.AAI3S.POIE/W\n",
      "O(  —  RA.NSM.O(\n",
      "QEO\\S  —  N2.NSM.QEO/S\n",
      "TO\\N  —  RA.ASM.O(\n",
      "OU)RANO\\N  —  N2.ASM.OU)RANO/S\n",
      "KAI\\  —  C.KAI/\n",
      "TH\\N  —  RA.ASF.O(\n",
      "GH=N  —  N1.ASF.GH=\n"
     ]
    }
   ],
   "source": [
    "genesis_1 = T.nodeFromSection(('Genesis', '1'))\n",
    "\n",
    "for word in L.d(genesis_1, otype='word')[:10]:\n",
    "    print(F.trans.v(word), ' — ', F.morph.v(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store new features here: feature_name to node to feature \n",
    "features = collections.defaultdict(dict)\n",
    "\n",
    "# conversion dicts\n",
    "typs = {'N': 'noun',\n",
    "        'V': 'verb',\n",
    "        'A': 'adjv',\n",
    "        'R': 'pron',\n",
    "        'C': 'conj',\n",
    "        'X': 'part',\n",
    "        'I': 'intj',\n",
    "        'M': 'inum',\n",
    "        'P': 'prep',\n",
    "        'D': 'advb'}\n",
    "       #'N': 'propn' proper noun, added below with special rule\n",
    "cases = {'N': 'nom',\n",
    "         'G': 'gen',\n",
    "         'D': 'dat',\n",
    "         'A': 'acc',\n",
    "         'V': 'voc'}\n",
    "numbers = {'S': 'sg',\n",
    "          'D': 'du',\n",
    "          'P': 'pl'}\n",
    "genders = {'M': 'm',\n",
    "          'F': 'f',\n",
    "          'N': 'n'}\n",
    "degrees = {'C': 'comparative',\n",
    "          'S': 'superlative'}\n",
    "tenses = {'P': 'present',\n",
    "         'I': 'imperfect',\n",
    "         'F': 'future',\n",
    "         'A': 'aorist',\n",
    "         'X': 'perfect',\n",
    "         'Y': 'pluperfect'}\n",
    "voices = {'A': 'active',\n",
    "         'M': 'middle',\n",
    "         'P': 'passsive'}\n",
    "moods = {'D': 'impv',\n",
    "        'S': 'subj',\n",
    "        'O': 'optv',\n",
    "        'N': 'infv',\n",
    "        'P': 'ptcp'}\n",
    "\n",
    "typ_counts = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "# big loop\n",
    "for word in F.otype.s('word'):\n",
    "    \n",
    "    morph = F.morph.v(word)\n",
    "    split_morph = morph.split('.')\n",
    "    \n",
    "    # parse morphology codes in order of appearance:\n",
    "    \n",
    "    # first position is always the type (part of speech):\n",
    "    styp = split_morph[0] # subtype\n",
    "    # get type:\n",
    "    if styp == 'N': # exception for proper nouns; nouns with no subtypes\n",
    "        typ = 'propn'\n",
    "    else:\n",
    "        typ = typs[styp[0]] # type is only first char of code, convert it\n",
    "    \n",
    "    # assign parsing data\n",
    "    #if len(split_morph) == 2: # indeclinable word\n",
    "    #    case, gender, number, degree, tense, voice, mood = ('na' for i in range(1,8))\n",
    "    \n",
    "    typ_counts[typ][len(split_morph)] += 1\n",
    "        \n",
    "len(typ_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x129140d90>,\n",
      "            {'adjv': Counter({3: 33656, 2: 6, 4: 2}),\n",
      "             'advb': Counter({2: 21091, 3: 13}),\n",
      "             'conj': Counter({2: 74270, 3: 4}),\n",
      "             'intj': Counter({2: 1385}),\n",
      "             'inum': Counter({2: 3360, 3: 193}),\n",
      "             'noun': Counter({3: 138910}),\n",
      "             'part': Counter({2: 8718}),\n",
      "             'prep': Counter({2: 54909}),\n",
      "             'pron': Counter({3: 158131, 2: 8, 4: 1}),\n",
      "             'propn': Counter({3: 27091, 2: 38, 4: 2}),\n",
      "             'verb': Counter({3: 65566, 4: 34635, 5: 1694, 6: 2})})\n"
     ]
    }
   ],
   "source": [
    "pprint(typ_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
